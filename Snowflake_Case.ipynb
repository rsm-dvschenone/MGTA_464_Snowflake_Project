{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /opt/conda/lib/python3.12/site-packages (24.2)\n",
      "Collecting pip\n",
      "  Downloading pip-25.2-py3-none-any.whl.metadata (4.7 kB)\n",
      "Downloading pip-25.2-py3-none-any.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m0m\n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 24.2\n",
      "    Uninstalling pip-24.2:\n",
      "      Successfully uninstalled pip-24.2\n",
      "Successfully installed pip-25.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting snowflake-connector-python<4,>=3\n",
      "  Using cached snowflake_connector_python-3.17.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (74 kB)\n",
      "Requirement already satisfied: python-dotenv in /opt/conda/lib/python3.12/site-packages (1.0.1)\n",
      "Collecting asn1crypto<2.0.0,>0.24.0 (from snowflake-connector-python<4,>=3)\n",
      "  Using cached asn1crypto-1.5.1-py2.py3-none-any.whl.metadata (13 kB)\n",
      "Collecting boto3>=1.24 (from snowflake-connector-python<4,>=3)\n",
      "  Using cached boto3-1.40.30-py3-none-any.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: botocore>=1.24 in /opt/conda/lib/python3.12/site-packages (from snowflake-connector-python<4,>=3) (1.35.90)\n",
      "Requirement already satisfied: cffi<2.0.0,>=1.9 in /opt/conda/lib/python3.12/site-packages (from snowflake-connector-python<4,>=3) (1.17.1)\n",
      "Requirement already satisfied: cryptography>=3.1.0 in /opt/conda/lib/python3.12/site-packages (from snowflake-connector-python<4,>=3) (43.0.3)\n",
      "Collecting pyOpenSSL<26.0.0,>=22.0.0 (from snowflake-connector-python<4,>=3)\n",
      "  Downloading pyopenssl-25.2.0-py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: pyjwt<3.0.0 in /opt/conda/lib/python3.12/site-packages (from snowflake-connector-python<4,>=3) (2.9.0)\n",
      "Requirement already satisfied: pytz in /opt/conda/lib/python3.12/site-packages (from snowflake-connector-python<4,>=3) (2024.1)\n",
      "Requirement already satisfied: requests<3.0.0 in /opt/conda/lib/python3.12/site-packages (from snowflake-connector-python<4,>=3) (2.32.3)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.12/site-packages (from snowflake-connector-python<4,>=3) (24.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.12/site-packages (from snowflake-connector-python<4,>=3) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.12/site-packages (from snowflake-connector-python<4,>=3) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.12/site-packages (from snowflake-connector-python<4,>=3) (2024.12.14)\n",
      "Requirement already satisfied: typing_extensions<5,>=4.3 in /opt/conda/lib/python3.12/site-packages (from snowflake-connector-python<4,>=3) (4.12.2)\n",
      "Requirement already satisfied: filelock<4,>=3.5 in /opt/conda/lib/python3.12/site-packages (from snowflake-connector-python<4,>=3) (3.16.1)\n",
      "Requirement already satisfied: sortedcontainers>=2.4.0 in /opt/conda/lib/python3.12/site-packages (from snowflake-connector-python<4,>=3) (2.4.0)\n",
      "Requirement already satisfied: platformdirs<5.0.0,>=2.6.0 in /opt/conda/lib/python3.12/site-packages (from snowflake-connector-python<4,>=3) (4.3.6)\n",
      "Requirement already satisfied: tomlkit in /opt/conda/lib/python3.12/site-packages (from snowflake-connector-python<4,>=3) (0.13.2)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.12/site-packages (from cffi<2.0.0,>=1.9->snowflake-connector-python<4,>=3) (2.22)\n",
      "Collecting cryptography>=3.1.0 (from snowflake-connector-python<4,>=3)\n",
      "  Downloading cryptography-45.0.7-cp311-abi3-manylinux_2_34_x86_64.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.12/site-packages (from requests<3.0.0->snowflake-connector-python<4,>=3) (2.2.3)\n",
      "Collecting botocore>=1.24 (from snowflake-connector-python<4,>=3)\n",
      "  Using cached botocore-1.40.30-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.12/site-packages (from boto3>=1.24->snowflake-connector-python<4,>=3) (1.0.1)\n",
      "Collecting s3transfer<0.15.0,>=0.14.0 (from boto3>=1.24->snowflake-connector-python<4,>=3)\n",
      "  Using cached s3transfer-0.14.0-py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.12/site-packages (from botocore>=1.24->snowflake-connector-python<4,>=3) (2.9.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil<3.0.0,>=2.1->botocore>=1.24->snowflake-connector-python<4,>=3) (1.16.0)\n",
      "Using cached snowflake_connector_python-3.17.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.7 MB)\n",
      "Using cached asn1crypto-1.5.1-py2.py3-none-any.whl (105 kB)\n",
      "Downloading pyopenssl-25.2.0-py3-none-any.whl (57 kB)\n",
      "Downloading cryptography-45.0.7-cp311-abi3-manylinux_2_34_x86_64.whl (4.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m784.9 kB/s\u001b[0m  \u001b[33m0:00:05\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached boto3-1.40.30-py3-none-any.whl (139 kB)\n",
      "Using cached botocore-1.40.30-py3-none-any.whl (14.0 MB)\n",
      "Using cached s3transfer-0.14.0-py3-none-any.whl (85 kB)\n",
      "Installing collected packages: asn1crypto, cryptography, botocore, s3transfer, pyOpenSSL, boto3, snowflake-connector-python\n",
      "\u001b[2K  Attempting uninstall: cryptography\n",
      "\u001b[2K    Found existing installation: cryptography 43.0.3\n",
      "\u001b[2K    Uninstalling cryptography-43.0.3:\n",
      "\u001b[2K      Successfully uninstalled cryptography-43.0.3━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/7\u001b[0m [cryptography]\n",
      "\u001b[2K  Attempting uninstall: botocore━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/7\u001b[0m [cryptography]\n",
      "\u001b[2K    Found existing installation: botocore 1.35.90━━━━━━━━━━━━━\u001b[0m \u001b[32m1/7\u001b[0m [cryptography]\n",
      "\u001b[2K    Uninstalling botocore-1.35.90:━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/7\u001b[0m [cryptography]\n",
      "\u001b[2K      Successfully uninstalled botocore-1.35.90━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/7\u001b[0m [botocore]\n",
      "\u001b[2K  Attempting uninstall: s3transfer[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/7\u001b[0m [botocore]\n",
      "\u001b[2K    Found existing installation: s3transfer 0.10.4━━━━━━━━━━━━\u001b[0m \u001b[32m2/7\u001b[0m [botocore]\n",
      "\u001b[2K    Uninstalling s3transfer-0.10.4:\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/7\u001b[0m [s3transfer]\n",
      "\u001b[2K      Successfully uninstalled s3transfer-0.10.4━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/7\u001b[0m [s3transfer]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7/7\u001b[0m [snowflake-connector-python]-connector-python]\n",
      "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "awscli 1.36.31 requires botocore==1.35.90, but you have botocore 1.40.30 which is incompatible.\n",
      "awscli 1.36.31 requires s3transfer<0.11.0,>=0.10.0, but you have s3transfer 0.14.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed asn1crypto-1.5.1 boto3-1.40.30 botocore-1.40.30 cryptography-45.0.7 pyOpenSSL-25.2.0 s3transfer-0.14.0 snowflake-connector-python-3.17.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade pip\n",
    "%pip install \"snowflake-connector-python>=3,<4\" python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import snowflake.connector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in /opt/conda/lib/python3.12/site-packages (1.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install python-dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "import os\n",
    "\n",
    "# Find and load the nearest .env (project root)\n",
    "load_dotenv(find_dotenv(), override=True)\n",
    "\n",
    "def need(name):\n",
    "    v = os.getenv(name)\n",
    "    if not v:\n",
    "        raise RuntimeError(f\"Missing required env var: {name}\")\n",
    "    # remove accidental quotes/spaces\n",
    "    return v.strip().strip('\"').strip(\"'\")\n",
    "\n",
    "SNOWFLAKE_USER     = need(\"SNOWFLAKE_USER\")\n",
    "SNOWFLAKE_PASSWORD = need(\"SNOWFLAKE_PASSWORD\")\n",
    "SNOWFLAKE_ACCOUNT  = need(\"SNOWFLAKE_ACCOUNT\")  # e.g., afaypkh-rjb48354\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import snowflake.connector\n",
    "\n",
    "conn = snowflake.connector.connect(\n",
    "    user=SNOWFLAKE_USER,\n",
    "    password=SNOWFLAKE_PASSWORD,\n",
    "    account=SNOWFLAKE_ACCOUNT,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<snowflake.connector.cursor.SnowflakeCursor at 0x73cd1002fa70>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cs.execute(\"CREATE WAREHOUSE IF NOT EXISTS my_first_warehouse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<snowflake.connector.cursor.SnowflakeCursor at 0x73cd1002fa70>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cs.execute(\"CREATE DATABASE IF NOT EXISTS testdb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 13\n",
      "\n",
      "Sample rows:\n",
      "(1, 'A Datum Corporation', '(847) 555-0100', 'http://www.adatum.com', None, None)\n",
      "(2, 'Contoso, Ltd.', '(360) 555-0100', 'http://www.contoso.com', None, None)\n",
      "(3, 'Consolidated Messenger', '(415) 555-0100', 'http://www.consolidatedmessenger.com', None, None)\n",
      "(4, 'Fabrikam, Inc.', '(203) 555-0104', 'http://www.fabrikam.com', None, None)\n",
      "(5, 'Graphic Design Institute', '(406) 555-0105', 'http://www.graphicdesigninstitute.com', None, None)\n",
      "(6, 'Humongous Insurance', '(423) 555-0105', 'http://www.humongousinsurance.com', None, None)\n",
      "(7, 'Litware, Inc.', '(209) 555-0108', 'http://www.litwareinc.com', None, None)\n",
      "(8, 'Lucerne Publishing', '(423) 555-0103', 'http://www.lucernepublishing.com', None, None)\n",
      "(9, 'Nod Publishers', '(252) 555-0100', 'http://www.nodpublishers.com', None, None)\n",
      "(10, 'Northwind Electric Cars', '(201) 555-0105', 'http://www.northwindelectriccars.com', None, None)\n",
      "\n",
      "Schema:\n",
      "SUPPLIERID NUMBER(38,0)\n",
      "SUPPLIERNAME VARCHAR(16777216)\n",
      "SUPPLIERCATEGORYID NUMBER(38,0)\n",
      "PRIMARYCONTACTPERSONID NUMBER(38,0)\n",
      "ALTERNATECONTACTPERSONID NUMBER(38,0)\n",
      "DELIVERYMETHODID NUMBER(38,0)\n",
      "POSTALCITYID NUMBER(38,0)\n",
      "SUPPLIERREFERENCE VARCHAR(16777216)\n",
      "BANKACCOUNTNAME VARCHAR(16777216)\n",
      "BANKACCOUNTBRANCH VARCHAR(16777216)\n",
      "BANKACCOUNTCODE NUMBER(38,0)\n",
      "BANKACCOUNTNUMBER NUMBER(38,0)\n",
      "BANKINTERNATIONALCODE NUMBER(38,0)\n",
      "PAYMENTDAYS NUMBER(38,0)\n",
      "INTERNALCOMMENTS VARCHAR(16777216)\n",
      "PHONENUMBER VARCHAR(16777216)\n",
      "FAXNUMBER VARCHAR(16777216)\n",
      "WEBSITEURL VARCHAR(16777216)\n",
      "DELIVERYADDRESSLINE1 VARCHAR(16777216)\n",
      "DELIVERYADDRESSLINE2 VARCHAR(16777216)\n",
      "DELIVERYPOSTALCODE NUMBER(38,0)\n",
      "DELIVERYLOCATION VARCHAR(16777216)\n",
      "POSTALADDRESSLINE1 VARCHAR(16777216)\n",
      "POSTALADDRESSLINE2 VARCHAR(16777216)\n",
      "POSTALPOSTALCODE NUMBER(38,0)\n",
      "LASTEDITEDBY NUMBER(38,0)\n",
      "VALIDFROM VARCHAR(16777216)\n",
      "VALIDTO VARCHAR(16777216)\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "# ---- 0) connect  ----\n",
    "conn = snowflake.connector.connect(\n",
    "    host=\"qbmhuza-bnb86629.snowflakecomputing.com\",   \n",
    "    account=\"qbmhuza-bnb86629\",                        \n",
    "    user=\"second2\",\n",
    "    password=\"gyczeg6kaHqywownor\",\n",
    "    warehouse=\"COMPUTE_WH\",                           \n",
    ")\n",
    "cs = conn.cursor()\n",
    "\n",
    "# make sure the warehouse will wake itself\n",
    "cs.execute(\"ALTER WAREHOUSE COMPUTE_WH SET AUTO_SUSPEND=60 AUTO_RESUME=TRUE\")\n",
    "\n",
    "# ---- 1) set DB/Schema (use your existing TESTDB) ----\n",
    "DB, SCHEMA = \"TESTDB\", \"PUBLIC\"\n",
    "cs.execute(f\"CREATE DATABASE IF NOT EXISTS {DB}\")\n",
    "cs.execute(f\"CREATE SCHEMA   IF NOT EXISTS {DB}.{SCHEMA}\")\n",
    "cs.execute(f\"USE DATABASE {DB}\")\n",
    "cs.execute(f\"USE SCHEMA {SCHEMA}\")\n",
    "\n",
    "# ---- 2) read and run your .pgsql file from the repo ----\n",
    "sql_path = Path(\"Data/supplier_case.pgsql\")     \n",
    "assert sql_path.exists(), f\"Not found: {sql_path.resolve()}\"\n",
    "txt = sql_path.read_text(encoding=\"utf-8\")\n",
    "\n",
    "# tiny Postgres -> Snowflake cleanups\n",
    "txt = \"\\n\".join(l for l in txt.splitlines() if not l.strip().startswith(\"\\\\\"))            # drop psql meta commands\n",
    "txt = re.sub(r\"\\bNUMERIC\\b\", \"NUMBER\", txt, flags=re.I)                                   # NUMERIC -> NUMBER (safe)\n",
    "txt = re.sub(r\"\\bsupplier_case\\b\", f\"{DB}.{SCHEMA}.SUPPLIER_CASE\", txt, flags=re.I)       # fully-qualify table\n",
    "\n",
    "# split on semicolons and execute\n",
    "stmts = [s.strip() for s in re.split(r\";\\s*(?=\\n|$)\", txt) if s.strip()]\n",
    "for s in stmts:\n",
    "    cs.execute(s)\n",
    "\n",
    "# ---- 3) visualize (still only cs.execute) ----\n",
    "print(\"Rows:\", cs.execute(f\"SELECT COUNT(*) FROM {DB}.{SCHEMA}.SUPPLIER_CASE\").fetchone()[0])\n",
    "\n",
    "print(\"\\nSample rows:\")\n",
    "for r in cs.execute(f\"\"\"\n",
    "    SELECT SupplierID, SupplierName, PhoneNumber, WebsiteURL,\n",
    "           TRY_TO_DATE(ValidFrom) AS ValidFrom, TRY_TO_DATE(ValidTo) AS ValidTo\n",
    "    FROM {DB}.{SCHEMA}.SUPPLIER_CASE\n",
    "    ORDER BY SupplierID\n",
    "    LIMIT 10\n",
    "\"\"\").fetchall():\n",
    "    print(r)\n",
    "\n",
    "print(\"\\nSchema:\")\n",
    "for r in cs.execute(f\"DESCRIBE TABLE {DB}.{SCHEMA}.SUPPLIER_CASE\").fetchall():\n",
    "    print(r[0], r[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<snowflake.connector.cursor.SnowflakeCursor at 0x73cd1002ff80>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cs.execute(\"USE DATABASE TESTDB\")\n",
    "cs.execute(\"USE SCHEMA PUBLIC\")\n",
    "\n",
    "cs.execute(\"\"\"\n",
    "CREATE OR REPLACE TABLE TESTDB.PUBLIC.SUPPLIER_CASE_CLEAN AS\n",
    "SELECT\n",
    "  CAST(SUPPLIERID               AS INT)        AS SUPPLIERID,\n",
    "  SUPPLIERNAME                                   AS SUPPLIERNAME,\n",
    "  CAST(SUPPLIERCATEGORYID       AS INT)        AS SUPPLIERCATEGORYID,\n",
    "  CAST(PRIMARYCONTACTPERSONID   AS INT)        AS PRIMARYCONTACTPERSONID,\n",
    "  CAST(ALTERNATECONTACTPERSONID AS INT)        AS ALTERNATECONTACTPERSONID,\n",
    "  CAST(DELIVERYMETHODID         AS INT)        AS DELIVERYMETHODID,\n",
    "  CAST(POSTALCITYID             AS INT)        AS POSTALCITYID,\n",
    "  SUPPLIERREFERENCE                              AS SUPPLIERREFERENCE,\n",
    "  PHONENUMBER                                   AS PHONENUMBER,\n",
    "  WEBSITEURL                                    AS WEBSITEURL,\n",
    "  DELIVERYADDRESSLINE1                           AS DELIVERYADDRESSLINE1,\n",
    "  CAST(DELIVERYPOSTALCODE       AS INT)        AS DELIVERYPOSTALCODE,\n",
    "  POSTALADDRESSLINE1                             AS POSTALADDRESSLINE1,\n",
    "  CAST(POSTALPOSTALCODE         AS INT)        AS POSTALPOSTALCODE,\n",
    "  CAST(LASTEDITEDBY             AS INT)        AS LASTEDITEDBY,\n",
    "  TRY_TO_DATE(VALIDFROM)                        AS VALIDFROM,\n",
    "  TRY_TO_DATE(VALIDTO)                          AS VALIDTO\n",
    "FROM TESTDB.PUBLIC.SUPPLIER_CASE;\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "(1, 'A Datum Corporation', '(847) 555-0100', 'http://www.adatum.com', None, None)\n",
      "(2, 'Contoso, Ltd.', '(360) 555-0100', 'http://www.contoso.com', None, None)\n",
      "(3, 'Consolidated Messenger', '(415) 555-0100', 'http://www.consolidatedmessenger.com', None, None)\n",
      "(4, 'Fabrikam, Inc.', '(203) 555-0104', 'http://www.fabrikam.com', None, None)\n",
      "(5, 'Graphic Design Institute', '(406) 555-0105', 'http://www.graphicdesigninstitute.com', None, None)\n",
      "(6, 'Humongous Insurance', '(423) 555-0105', 'http://www.humongousinsurance.com', None, None)\n",
      "(7, 'Litware, Inc.', '(209) 555-0108', 'http://www.litwareinc.com', None, None)\n",
      "(8, 'Lucerne Publishing', '(423) 555-0103', 'http://www.lucernepublishing.com', None, None)\n",
      "(9, 'Nod Publishers', '(252) 555-0100', 'http://www.nodpublishers.com', None, None)\n",
      "(10, 'Northwind Electric Cars', '(201) 555-0105', 'http://www.northwindelectriccars.com', None, None)\n"
     ]
    }
   ],
   "source": [
    "print(cs.execute(\"SELECT COUNT(*) FROM TESTDB.PUBLIC.SUPPLIER_CASE_CLEAN\").fetchone()[0])\n",
    "for r in cs.execute(\"\"\"\n",
    "  SELECT SUPPLIERID, SUPPLIERNAME, PHONENUMBER, WEBSITEURL, VALIDFROM, VALIDTO\n",
    "  FROM TESTDB.PUBLIC.SUPPLIER_CASE_CLEAN\n",
    "  ORDER BY SUPPLIERID\n",
    "  LIMIT 10\n",
    "\"\"\").fetchall():\n",
    "    print(r)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import snowflake.connector\n",
    "\n",
    "def find_weather_db(cs):\n",
    "    # Get all db names\n",
    "    names = [r[1] for r in cs.execute(\"SHOW DATABASES\").fetchall()]\n",
    "    # Try exact names from the brief\n",
    "    for cand in (\"WEATHER__ENVIRONMENT\", \"WEATHER_ENVIRONMENT\"):\n",
    "        if cand in names:\n",
    "            return cand\n",
    "    # Fuzzy fallback (handles custom names)\n",
    "    for n in names:\n",
    "        if \"WEATHER\" in n and \"ENVIRONMENT\" in n:\n",
    "            return n\n",
    "    return None\n",
    "\n",
    "def print_table_sample(cs, fqtn, sample_rows=5):\n",
    "    print(f\"\\n=== {fqtn} ===\")\n",
    "    cs.execute(f\"SELECT * FROM {fqtn} LIMIT {sample_rows}\")\n",
    "    rows = cs.fetchall()\n",
    "    cols = [d[0] for d in cs.description]\n",
    "    print(\"Columns:\", \", \".join(cols))\n",
    "    for i, r in enumerate(rows, 1):\n",
    "        print(f\"{i:>2}: {r}\")\n",
    "    cs.execute(f\"SELECT COUNT(*) FROM {fqtn}\")\n",
    "    print(\"Total rows:\", cs.fetchone()[0])\n",
    "\n",
    "def print_cybersyn_weather_tables(conn, warehouse=\"COMPUTE_WH\"):\n",
    "    with conn.cursor() as cs:\n",
    "        cs.execute(f\"USE WAREHOUSE {warehouse}\")\n",
    "\n",
    "        db_name = find_weather_db(cs)\n",
    "        if not db_name:\n",
    "            print(\"⚠️  Skipping Cybersyn weather: no WEATHER…ENVIRONMENT database found in this account.\")\n",
    "            have = [r[1] for r in cs.execute(\"SHOW DATABASES\").fetchall()]\n",
    "            print(\"Databases you have:\", have)\n",
    "            return\n",
    "\n",
    "        cs.execute(f\"USE DATABASE {db_name}\")\n",
    "\n",
    "        # Prefer CYBERSYN schema if present; otherwise fall back to PUBLIC\n",
    "        schemas = {r[1] for r in cs.execute(f\"SHOW SCHEMAS IN DATABASE {db_name}\").fetchall()}\n",
    "        schema = \"CYBERSYN\" if \"CYBERSYN\" in schemas else \"PUBLIC\"\n",
    "        cs.execute(f\"USE SCHEMA {schema}\")\n",
    "\n",
    "        # If the exact NOAA table names differ, list what’s there and pick two NOAA* tables\n",
    "        all_tables = [r[1] for r in cs.execute(f\"SHOW TABLES IN SCHEMA {db_name}.{schema}\").fetchall()]\n",
    "        candidates = [t for t in all_tables if t.startswith(\"NOAA_\")]\n",
    "        if not candidates:\n",
    "            print(f\"No NOAA_* tables in {db_name}.{schema}. Available tables:\", all_tables)\n",
    "            return\n",
    "\n",
    "        for t in candidates[:2]:\n",
    "            print_table_sample(cs, f\"{db_name}.{schema}.{t}\", sample_rows=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import snowflake.connector\n",
    "\n",
    "conn = snowflake.connector.connect(\n",
    "    user=SNOWFLAKE_USER,\n",
    "    password=SNOWFLAKE_PASSWORD,\n",
    "    account=SNOWFLAKE_ACCOUNT,\n",
    ")\n",
    "cs = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using data folder: /home/jovyan/UCSD CLASSES/MGTA 464- SQL/MGTA_464_Snowflake_Project/Data/Monthly PO Data\n",
      "Matched CSVs: 41\n",
      "PUT -> file:///home/jovyan/UCSD CLASSES/MGTA 464- SQL/MGTA_464_Snowflake_Project/Data/Monthly PO Data/2019-6.csv\n",
      "PUT -> file:///home/jovyan/UCSD CLASSES/MGTA 464- SQL/MGTA_464_Snowflake_Project/Data/Monthly PO Data/2021-10.csv\n",
      "PUT -> file:///home/jovyan/UCSD CLASSES/MGTA 464- SQL/MGTA_464_Snowflake_Project/Data/Monthly PO Data/2020-1.csv\n",
      "PUT -> file:///home/jovyan/UCSD CLASSES/MGTA 464- SQL/MGTA_464_Snowflake_Project/Data/Monthly PO Data/2022-3.csv\n",
      "PUT -> file:///home/jovyan/UCSD CLASSES/MGTA 464- SQL/MGTA_464_Snowflake_Project/Data/Monthly PO Data/2021-1.csv\n",
      "PUT -> file:///home/jovyan/UCSD CLASSES/MGTA 464- SQL/MGTA_464_Snowflake_Project/Data/Monthly PO Data/2020-8.csv\n",
      "PUT -> file:///home/jovyan/UCSD CLASSES/MGTA 464- SQL/MGTA_464_Snowflake_Project/Data/Monthly PO Data/2021-7.csv\n",
      "PUT -> file:///home/jovyan/UCSD CLASSES/MGTA 464- SQL/MGTA_464_Snowflake_Project/Data/Monthly PO Data/2021-5.csv\n",
      "PUT -> file:///home/jovyan/UCSD CLASSES/MGTA 464- SQL/MGTA_464_Snowflake_Project/Data/Monthly PO Data/2020-7.csv\n",
      "PUT -> file:///home/jovyan/UCSD CLASSES/MGTA 464- SQL/MGTA_464_Snowflake_Project/Data/Monthly PO Data/2020-9.csv\n",
      "PUT -> file:///home/jovyan/UCSD CLASSES/MGTA 464- SQL/MGTA_464_Snowflake_Project/Data/Monthly PO Data/2021-12.csv\n",
      "PUT -> file:///home/jovyan/UCSD CLASSES/MGTA 464- SQL/MGTA_464_Snowflake_Project/Data/Monthly PO Data/2019-2.csv\n",
      "PUT -> file:///home/jovyan/UCSD CLASSES/MGTA 464- SQL/MGTA_464_Snowflake_Project/Data/Monthly PO Data/2020-6.csv\n",
      "PUT -> file:///home/jovyan/UCSD CLASSES/MGTA 464- SQL/MGTA_464_Snowflake_Project/Data/Monthly PO Data/2019-10.csv\n",
      "PUT -> file:///home/jovyan/UCSD CLASSES/MGTA 464- SQL/MGTA_464_Snowflake_Project/Data/Monthly PO Data/2020-12.csv\n",
      "PUT -> file:///home/jovyan/UCSD CLASSES/MGTA 464- SQL/MGTA_464_Snowflake_Project/Data/Monthly PO Data/2019-3.csv\n",
      "PUT -> file:///home/jovyan/UCSD CLASSES/MGTA 464- SQL/MGTA_464_Snowflake_Project/Data/Monthly PO Data/2019-5.csv\n",
      "PUT -> file:///home/jovyan/UCSD CLASSES/MGTA 464- SQL/MGTA_464_Snowflake_Project/Data/Monthly PO Data/2019-11.csv\n",
      "PUT -> file:///home/jovyan/UCSD CLASSES/MGTA 464- SQL/MGTA_464_Snowflake_Project/Data/Monthly PO Data/2022-5.csv\n",
      "PUT -> file:///home/jovyan/UCSD CLASSES/MGTA 464- SQL/MGTA_464_Snowflake_Project/Data/Monthly PO Data/2021-3.csv\n",
      "PUT -> file:///home/jovyan/UCSD CLASSES/MGTA 464- SQL/MGTA_464_Snowflake_Project/Data/Monthly PO Data/2020-2.csv\n",
      "PUT -> file:///home/jovyan/UCSD CLASSES/MGTA 464- SQL/MGTA_464_Snowflake_Project/Data/Monthly PO Data/2019-4.csv\n",
      "PUT -> file:///home/jovyan/UCSD CLASSES/MGTA 464- SQL/MGTA_464_Snowflake_Project/Data/Monthly PO Data/2020-4.csv\n",
      "PUT -> file:///home/jovyan/UCSD CLASSES/MGTA 464- SQL/MGTA_464_Snowflake_Project/Data/Monthly PO Data/2022-2.csv\n",
      "PUT -> file:///home/jovyan/UCSD CLASSES/MGTA 464- SQL/MGTA_464_Snowflake_Project/Data/Monthly PO Data/2021-11.csv\n",
      "PUT -> file:///home/jovyan/UCSD CLASSES/MGTA 464- SQL/MGTA_464_Snowflake_Project/Data/Monthly PO Data/2022-1.csv\n",
      "PUT -> file:///home/jovyan/UCSD CLASSES/MGTA 464- SQL/MGTA_464_Snowflake_Project/Data/Monthly PO Data/2019-8.csv\n",
      "PUT -> file:///home/jovyan/UCSD CLASSES/MGTA 464- SQL/MGTA_464_Snowflake_Project/Data/Monthly PO Data/2021-6.csv\n",
      "PUT -> file:///home/jovyan/UCSD CLASSES/MGTA 464- SQL/MGTA_464_Snowflake_Project/Data/Monthly PO Data/2021-8.csv\n",
      "PUT -> file:///home/jovyan/UCSD CLASSES/MGTA 464- SQL/MGTA_464_Snowflake_Project/Data/Monthly PO Data/2021-9.csv\n",
      "PUT -> file:///home/jovyan/UCSD CLASSES/MGTA 464- SQL/MGTA_464_Snowflake_Project/Data/Monthly PO Data/2019-7.csv\n",
      "PUT -> file:///home/jovyan/UCSD CLASSES/MGTA 464- SQL/MGTA_464_Snowflake_Project/Data/Monthly PO Data/2020-11.csv\n",
      "PUT -> file:///home/jovyan/UCSD CLASSES/MGTA 464- SQL/MGTA_464_Snowflake_Project/Data/Monthly PO Data/2022-4.csv\n",
      "PUT -> file:///home/jovyan/UCSD CLASSES/MGTA 464- SQL/MGTA_464_Snowflake_Project/Data/Monthly PO Data/2020-5.csv\n",
      "PUT -> file:///home/jovyan/UCSD CLASSES/MGTA 464- SQL/MGTA_464_Snowflake_Project/Data/Monthly PO Data/2019-12.csv\n",
      "PUT -> file:///home/jovyan/UCSD CLASSES/MGTA 464- SQL/MGTA_464_Snowflake_Project/Data/Monthly PO Data/2021-4.csv\n",
      "PUT -> file:///home/jovyan/UCSD CLASSES/MGTA 464- SQL/MGTA_464_Snowflake_Project/Data/Monthly PO Data/2020-10.csv\n",
      "PUT -> file:///home/jovyan/UCSD CLASSES/MGTA 464- SQL/MGTA_464_Snowflake_Project/Data/Monthly PO Data/2019-9.csv\n",
      "PUT -> file:///home/jovyan/UCSD CLASSES/MGTA 464- SQL/MGTA_464_Snowflake_Project/Data/Monthly PO Data/2021-2.csv\n",
      "PUT -> file:///home/jovyan/UCSD CLASSES/MGTA 464- SQL/MGTA_464_Snowflake_Project/Data/Monthly PO Data/2020-3.csv\n",
      "PUT -> file:///home/jovyan/UCSD CLASSES/MGTA 464- SQL/MGTA_464_Snowflake_Project/Data/Monthly PO Data/2019-1.csv\n",
      "Staged objects (top 10): [('po_data_stage/2019-1.csv.gz', 6784, 'a15f2fa77d98a431c564917c46a8f54f', 'Sun, 14 Sep 2025 21:57:56 GMT'), ('po_data_stage/2019-10.csv.gz', 3328, '30fddf0b054c15abdf58d9008cfd507d', 'Sun, 14 Sep 2025 21:57:42 GMT'), ('po_data_stage/2019-11.csv.gz', 3056, 'cea00f90062fda98ac3b9cf93003f446', 'Sun, 14 Sep 2025 21:57:44 GMT'), ('po_data_stage/2019-12.csv.gz', 2992, 'f7f2bf307ed9bc4844dac53cbd45e6e6', 'Sun, 14 Sep 2025 21:57:53 GMT'), ('po_data_stage/2019-2.csv.gz', 2384, 'c63aedaf830d7dba4e7080fcd8b2fd8a', 'Sun, 14 Sep 2025 21:57:40 GMT'), ('po_data_stage/2019-3.csv.gz', 2848, 'dc2ccfb5cad11094f2139c3bd04bfb5e', 'Sun, 14 Sep 2025 21:57:43 GMT'), ('po_data_stage/2019-4.csv.gz', 3088, '8c7471de208492d2a57559e77a1b148d', 'Sun, 14 Sep 2025 21:57:46 GMT'), ('po_data_stage/2019-5.csv.gz', 3200, '8c01985520ab970c77732bd8a2d88a9d', 'Sun, 14 Sep 2025 21:57:44 GMT'), ('po_data_stage/2019-6.csv.gz', 3024, 'f926b36f2e78f5ec00e1b688260f5d9e', 'Sun, 14 Sep 2025 21:57:31 GMT'), ('po_data_stage/2019-7.csv.gz', 3264, 'ec2a86136f0ff8bf13eeeac1ded84faa', 'Sun, 14 Sep 2025 21:57:51 GMT')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<snowflake.connector.cursor.SnowflakeCursor at 0x73cd100688f0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, glob\n",
    "from pathlib import Path\n",
    "\n",
    "## Creating the PO_Table with Datatypes \n",
    "cs.execute(f\"USE DATABASE {DB}\")\n",
    "cs.execute(f\"USE SCHEMA {SCHEMA}\")\n",
    "cs.execute(\n",
    "\"CREATE OR REPLACE TABLE PO_Data(\"\n",
    "\"purchaseorderid NUMBER(38,0), \"\n",
    "\"supplierid NUMBER(38,0), \"\n",
    "\"orderdate DATE, \"\n",
    "\"deliverymethodid NUMBER(38,0), \"\n",
    "\"contactpersonid NUMBER(38,0), \"\n",
    "\"expecteddeliverydate DATE, \"\n",
    "\"supplierreference VARCHAR, \"\n",
    "\"isorderfinalized NUMBER(1,0), \"\n",
    "\"comments VARCHAR, \"\n",
    "\"internalcomments VARCHAR, \"\n",
    "\"lasteditedby NUMBER(38,0), \"\n",
    "\"purchaseorderlineid NUMBER(38,0), \"\n",
    "\"stockitemid NUMBER(38,0), \"\n",
    "\"orderedouters NUMBER(38,0), \"\n",
    "\"description VARCHAR, \"\n",
    "\"receivedouters NUMBER(38,0), \"\n",
    "\"packagetypeid NUMBER(38,0), \"\n",
    "\"expectedunitpriceperouter NUMBER(18,4), \"\n",
    "\"lastreceiptdate DATE, \"\n",
    "\"isorderlinefinalized NUMBER(1,0), \"\n",
    "\"right_lasteditedby NUMBER(38,0), \"\n",
    "\"right_lasteditedwhen TIMESTAMP_NTZ\"\n",
    "\")\")\n",
    "\n",
    "# ---------- Resolve repo-relative data folder ----------\n",
    "def find_monthly_po_dir() -> Path:\n",
    "    \"\"\"\n",
    "    Locate the 'Data/Monthly PO Data' folder relative to the repository.\n",
    "    Works from notebooks or scripts, on Windows/macOS/Linux.\n",
    "    \"\"\"\n",
    "    candidates = [\n",
    "        Path.cwd() / \"Data\" / \"Monthly PO Data\",\n",
    "        Path.cwd() / \"data\" / \"Monthly PO Data\",\n",
    "    ]\n",
    "\n",
    "    # If running from a subfolder, search upward then rglob for the directory\n",
    "    # 1) Walk up to (at most) 5 levels to find a '.git' folder (repo root)\n",
    "    here = Path.cwd()\n",
    "    ups = [here] + list(here.parents)[:5]\n",
    "    repo_roots = [p for p in ups if (p / \".git\").exists()]\n",
    "    roots_to_search = repo_roots[:1] or [here]\n",
    "\n",
    "    for root in roots_to_search:\n",
    "        candidates.append(root / \"Data\" / \"Monthly PO Data\")\n",
    "        candidates.append(root / \"data\" / \"Monthly PO Data\")\n",
    "        # fallback: recursive search for the exact folder name\n",
    "        for p in root.rglob(\"Monthly PO Data\"):\n",
    "            candidates.append(p)\n",
    "\n",
    "    for p in candidates:\n",
    "        if p.exists() and p.is_dir():\n",
    "            # Must contain CSVs to be considered valid\n",
    "            if any(p.glob(\"*.csv\")):\n",
    "                return p\n",
    "\n",
    "    raise SystemExit(\"Could not find 'Data/Monthly PO Data' in this repo. \"\n",
    "                     \"Make sure the data folder exists and contains .csv files.\")\n",
    "\n",
    "local_dir_path = find_monthly_po_dir()\n",
    "local_dir = str(local_dir_path)  # keep your existing code style\n",
    "print(\"Using data folder:\", local_dir)\n",
    "\n",
    "# ---------- Stage + file format ----------\n",
    "\n",
    "\n",
    "cs.execute(\"CREATE OR REPLACE STAGE po_data_stage\")\n",
    "cs.execute(\"\"\"\n",
    "CREATE OR REPLACE FILE FORMAT po_csv_ff\n",
    "  TYPE=CSV\n",
    "  FIELD_DELIMITER=','\n",
    "  FIELD_OPTIONALLY_ENCLOSED_BY='\"'\n",
    "  SKIP_HEADER=1\n",
    "  TRIM_SPACE=TRUE\n",
    "  EMPTY_FIELD_AS_NULL=TRUE\n",
    "  NULL_IF=('','NULL','null','00:00.0','0:00.0','00:00','0:00')\n",
    "  DATE_FORMAT='AUTO'\n",
    "  TIME_FORMAT='AUTO'\n",
    "  TIMESTAMP_FORMAT='AUTO'\n",
    "\"\"\")\n",
    "\n",
    "# ---------- Local files to stage (repo-relative) ----------\n",
    "\n",
    "pattern = os.path.join(local_dir, \"*.csv\")\n",
    "files = glob.glob(pattern)\n",
    "print(\"Matched CSVs:\", len(files))\n",
    "if not files:\n",
    "    raise SystemExit(f\"No CSVs matched at: {pattern}\")\n",
    "\n",
    "# ---------- PUT files into stage (auto-compress -> .gz) ----------\n",
    "for filepath in files:\n",
    "    base = os.path.basename(filepath)\n",
    "    if \":\" in base:   # skip Windows ADS like ':Zone.Identifier'\n",
    "        continue\n",
    "    abs_path = os.path.abspath(filepath).replace(\"\\\\\", \"/\")   # ensure forward slashes\n",
    "    file_uri = \"file:///\" + abs_path.lstrip(\"/\")              # exactly 3 slashes, no URL-encoding\n",
    "    print(\"PUT ->\", file_uri)\n",
    "    cs.execute(f\"PUT '{file_uri}' @po_data_stage AUTO_COMPRESS=TRUE OVERWRITE=TRUE\")\n",
    "    \n",
    "\n",
    "# --- sanity check what's in the stage ---\n",
    "cs.execute(\"LIST @po_data_stage\")\n",
    "print(\"Staged objects (top 10):\", cs.fetchall()[:10])\n",
    "\n",
    "# --- load into the table (skipping $12 = lasteditedwhen) ---\n",
    "cs.execute(\"\"\"\n",
    "COPY INTO PO_Data\n",
    "  FROM (\n",
    "    SELECT\n",
    "      $1  ::NUMBER(38,0)  AS purchaseorderid,\n",
    "      $2  ::NUMBER(38,0)  AS supplierid,\n",
    "      TRY_TO_DATE($3)     AS orderdate,\n",
    "      $4  ::NUMBER(38,0)  AS deliverymethodid,\n",
    "      $5  ::NUMBER(38,0)  AS contactpersonid,\n",
    "      TRY_TO_DATE($6)     AS expecteddeliverydate,\n",
    "      $7                  AS supplierreference,\n",
    "      $8  ::NUMBER(1,0)   AS isorderfinalized,\n",
    "      $9                  AS comments,\n",
    "      $10                 AS internalcomments,\n",
    "      $11 ::NUMBER(38,0)  AS lasteditedby,\n",
    "      /* skip $12 */\n",
    "      $13 ::NUMBER(38,0)  AS purchaseorderlineid,\n",
    "      $14 ::NUMBER(38,0)  AS stockitemid,\n",
    "      $15 ::NUMBER(38,0)  AS orderedouters,\n",
    "      $16                 AS description,\n",
    "      $17 ::NUMBER(38,0)  AS receivedouters,\n",
    "      $18 ::NUMBER(38,0)  AS packagetypeid,\n",
    "      $19 ::NUMBER(18,4)  AS expectedunitpriceperouter,\n",
    "      TRY_TO_DATE($20)    AS lastreceiptdate,\n",
    "      $21 ::NUMBER(1,0)   AS isorderlinefinalized,\n",
    "      $22 ::NUMBER(38,0)  AS right_lasteditedby,\n",
    "      TRY_TO_TIMESTAMP_NTZ($23) AS right_lasteditedwhen\n",
    "    FROM @po_data_stage (FILE_FORMAT => 'po_csv_ff')\n",
    "  )\n",
    "  ON_ERROR = ABORT_STATEMENT\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row count: 8367\n",
      "Row count should equal 8367\n"
     ]
    }
   ],
   "source": [
    "cs.execute(\"SELECT COUNT(*) FROM PO_Data\")\n",
    "print(\"Row count:\", cs.fetchone()[0])\n",
    "print(\"Row count should equal 8367\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(558, 4, datetime.date(2019, 12, 2), 7, 2, datetime.date(2019, 12, 22), '293092', 1, None, None, 8, 2160, 77, 767, '\"The Gu\" red shirt XML tag t-shirt (White) XXS', 767, 6, Decimal('84.0000'), datetime.date(2019, 12, 3), 1, 8, None)\n",
      "(558, 4, datetime.date(2019, 12, 2), 7, 2, datetime.date(2019, 12, 22), '293092', 1, None, None, 8, 2161, 78, 981, '\"The Gu\" red shirt XML tag t-shirt (White) XS', 981, 6, Decimal('84.0000'), datetime.date(2019, 12, 3), 1, 8, None)\n",
      "(558, 4, datetime.date(2019, 12, 2), 7, 2, datetime.date(2019, 12, 22), '293092', 1, None, None, 8, 2162, 80, 397, '\"The Gu\" red shirt XML tag t-shirt (White) M', 397, 6, Decimal('84.0000'), datetime.date(2019, 12, 3), 1, 8, None)\n",
      "(558, 4, datetime.date(2019, 12, 2), 7, 2, datetime.date(2019, 12, 22), '293092', 1, None, None, 8, 2163, 86, 816, '\"The Gu\" red shirt XML tag t-shirt (White) 5XL', 816, 6, Decimal('96.0000'), datetime.date(2019, 12, 3), 1, 8, None)\n",
      "(558, 4, datetime.date(2019, 12, 2), 7, 2, datetime.date(2019, 12, 22), '293092', 1, None, None, 8, 2164, 95, 521, '\"The Gu\" red shirt XML tag t-shirt (Black) XL', 521, 6, Decimal('90.0000'), datetime.date(2019, 12, 3), 1, 8, None)\n",
      "(558, 4, datetime.date(2019, 12, 2), 7, 2, datetime.date(2019, 12, 22), '293092', 1, None, None, 8, 2165, 98, 978, '\"The Gu\" red shirt XML tag t-shirt (Black) 4XL', 978, 6, Decimal('96.0000'), datetime.date(2019, 12, 3), 1, 8, None)\n",
      "(559, 7, datetime.date(2019, 12, 2), 2, 2, datetime.date(2019, 12, 22), 'BC0280982', 1, None, None, 8, 2166, 193, 344, 'Black and orange glass with care despatch tape 48mmx75m', 344, 7, Decimal('38.4000'), datetime.date(2019, 12, 3), 1, 8, None)\n",
      "(559, 7, datetime.date(2019, 12, 2), 2, 2, datetime.date(2019, 12, 22), 'BC0280982', 1, None, None, 8, 2167, 204, 467, 'Tape dispenser (Red)', 467, 7, Decimal('170.0000'), datetime.date(2019, 12, 3), 1, 8, None)\n",
      "(560, 4, datetime.date(2019, 12, 3), 7, 2, datetime.date(2019, 12, 23), '293092', 1, None, None, 17, 2168, 77, 769, '\"The Gu\" red shirt XML tag t-shirt (White) XXS', 769, 6, Decimal('84.0000'), datetime.date(2019, 12, 4), 1, 17, None)\n",
      "(560, 4, datetime.date(2019, 12, 3), 7, 2, datetime.date(2019, 12, 23), '293092', 1, None, None, 17, 2169, 78, 979, '\"The Gu\" red shirt XML tag t-shirt (White) XS', 979, 6, Decimal('84.0000'), datetime.date(2019, 12, 4), 1, 17, None)\n"
     ]
    }
   ],
   "source": [
    "cs.execute(\"SELECT * FROM PO_Data LIMIT 10\")\n",
    "for row in cs.fetchall():\n",
    "    print(row)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) PO totals (POAmount) and a tidy PO header table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<snowflake.connector.cursor.SnowflakeCursor at 0x73cd100688f0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One row per purchase order with the required total\n",
    "cs.execute(\"\"\"\n",
    "CREATE OR REPLACE VIEW PO_Header AS\n",
    "SELECT\n",
    "  purchaseorderid,\n",
    "  MIN(orderdate)                 AS orderdate,\n",
    "  MIN(supplierid)                AS supplierid,\n",
    "  SUM(receivedouters * expectedunitpriceperouter) AS POAmount\n",
    "FROM PO_Data\n",
    "GROUP BY purchaseorderid;\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local file URI: file:///home/jovyan/sf_uploads/supplier_transactions.xml\n",
      "[('invoice_xml_stage/supplier_transactions.xml.gz', 72528, '15c0f8f4276bf24ac457fb4e00e4107a', 'Sun, 14 Sep 2025 22:40:45 GMT')]\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "# Path to the XML in your repo (adjust this if your folder name differs)\n",
    "repo_xml = Path(\"Data\") / \"Supplier Transactions XML.xml\"\n",
    "\n",
    "# Make a simple, safe upload path that definitely exists *inside the container*\n",
    "safe_dir = Path.home() / \"sf_uploads\"\n",
    "safe_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "safe = safe_dir / \"supplier_transactions.xml\"   # normalize name\n",
    "shutil.copy2(repo_xml, safe)                     # copy into place\n",
    "\n",
    "uri = safe.as_uri()  # e.g., file:///home/jovyan/sf_uploads/supplier_transactions.xml\n",
    "print(\"Local file URI:\", uri)\n",
    "\n",
    "# Make sure the stage exists and is an *internal* stage\n",
    "cs.execute(\"CREATE STAGE IF NOT EXISTS invoice_xml_stage\")\n",
    "\n",
    "# Do the PUT\n",
    "cs.execute(f\"PUT '{uri}' @invoice_xml_stage OVERWRITE=TRUE AUTO_COMPRESS=TRUE\")\n",
    "\n",
    "# Confirm\n",
    "print(cs.execute(\"LIST @invoice_xml_stage\").fetchall())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xml_ff (with STRIP_OUTER_ELEMENT=TRUE) ready.\n"
     ]
    }
   ],
   "source": [
    "# 1) Recreate the XML file format WITH strip_outer_element\n",
    "cs.execute(\"\"\"\n",
    "CREATE OR REPLACE FILE FORMAT xml_ff\n",
    "  TYPE=XML\n",
    "  STRIP_OUTER_ELEMENT=TRUE\n",
    "\"\"\")\n",
    "print(\"xml_ff (with STRIP_OUTER_ELEMENT=TRUE) ready.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INVOICE_RAW rows (should be ~2438): 2438\n"
     ]
    }
   ],
   "source": [
    "# 2) Reload the XML so each <row> is its own table row\n",
    "cs.execute(\"CREATE OR REPLACE TABLE INVOICE_RAW (doc VARIANT)\")\n",
    "cs.execute(\"\"\"\n",
    "COPY INTO INVOICE_RAW\n",
    "FROM @invoice_xml_stage\n",
    "FILE_FORMAT = xml_ff\n",
    "ON_ERROR = ABORT_STATEMENT\n",
    "\"\"\")\n",
    "print(\"INVOICE_RAW rows (should be ~2438):\", cs.execute(\"SELECT COUNT(*) FROM INVOICE_RAW\").fetchone()[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows in SUPPLIER_INVOICES: 2438\n",
      "[(134, 2, 5, 1, '7290', datetime.date(2019, 1, 2), Decimal('313.50'), Decimal('47.03'), Decimal('360.53'), Decimal('0.00'), datetime.date(2019, 1, 7), True), (169, 4, 5, 2, '3898', datetime.date(2019, 1, 2), Decimal('21732.00'), Decimal('3259.80'), Decimal('24991.80'), Decimal('0.00'), datetime.date(2019, 1, 7), True), (186, 5, 5, 3, '616', datetime.date(2019, 1, 2), Decimal('2740.50'), Decimal('411.11'), Decimal('3151.61'), Decimal('0.00'), datetime.date(2019, 1, 7), True), (215, 7, 5, 4, '3869', datetime.date(2019, 1, 2), Decimal('42481.20'), Decimal('6372.19'), Decimal('48853.39'), Decimal('0.00'), datetime.date(2019, 1, 7), True), (224, 10, 5, 5, '4697', datetime.date(2019, 1, 2), Decimal('35067.50'), Decimal('5260.14'), Decimal('40327.64'), Decimal('0.00'), datetime.date(2019, 1, 7), True)]\n"
     ]
    }
   ],
   "source": [
    "cs.execute(\"\"\"\n",
    "CREATE OR REPLACE TABLE SUPPLIER_INVOICES AS\n",
    "SELECT\n",
    "  TRY_TO_NUMBER(XMLGET(doc,'SupplierTransactionID'):\"$\"::STRING)      AS SupplierTransactionID,\n",
    "  TRY_TO_NUMBER(XMLGET(doc,'SupplierID'):\"$\"::STRING)                  AS SupplierID,\n",
    "  TRY_TO_NUMBER(XMLGET(doc,'TransactionTypeID'):\"$\"::STRING)           AS TransactionTypeID,\n",
    "  NULLIF(XMLGET(doc,'PurchaseOrderID'):\"$\"::STRING,'')::NUMBER         AS PurchaseOrderID,\n",
    "  NULLIF(XMLGET(doc,'SupplierInvoiceNumber'):\"$\"::STRING,'')           AS SupplierInvoiceNumber,\n",
    "  TRY_TO_DATE(XMLGET(doc,'TransactionDate'):\"$\"::STRING)               AS TransactionDate,   -- safer\n",
    "  TRY_TO_DECIMAL(XMLGET(doc,'AmountExcludingTax'):\"$\"::STRING,18,2)    AS AmountExcludingTax,\n",
    "  TRY_TO_DECIMAL(XMLGET(doc,'TaxAmount'):\"$\"::STRING,18,2)             AS TaxAmount,\n",
    "  TRY_TO_DECIMAL(XMLGET(doc,'TransactionAmount'):\"$\"::STRING,18,2)     AS TransactionAmount,\n",
    "  TRY_TO_DECIMAL(XMLGET(doc,'OutstandingBalance'):\"$\"::STRING,18,2)    AS OutstandingBalance,\n",
    "  TRY_TO_DATE(XMLGET(doc,'FinalizationDate'):\"$\"::STRING)              AS FinalizationDate,\n",
    "  TRY_TO_BOOLEAN(XMLGET(doc,'IsFinalized'):\"$\"::STRING)                AS IsFinalized\n",
    "FROM INVOICE_RAW\n",
    "\"\"\")\n",
    "\n",
    "print(\"Rows in SUPPLIER_INVOICES:\", cs.execute(\"SELECT COUNT(*) FROM SUPPLIER_INVOICES\").fetchone()[0])\n",
    "print(cs.execute(\"SELECT * FROM SUPPLIER_INVOICES LIMIT 5\").fetchall())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
